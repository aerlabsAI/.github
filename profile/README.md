<p align="center">
  <picture>
    <img alt="AerLabs" src="https://aerlabs.tech/logo.png" width="300">
  </picture>
</p>

<h3 align="center">
AER: Accelerate Efficient Research | AI Engineering & Research
</h3>

<p align="center">
A high-throughput, full-stack open AI research lab optimizing the critical bottlenecks of AI systems.
</p>

<p align="center">
  <a href="https://aerlabs.tech/research.html">
    <img src="https://img.shields.io/badge/Researchers-60+-blue?style=flat&logo=google-scholar&logoColor=white" alt="Researchers">
  </a>
  <a href="https://aerlabs.tech/index.html">
    <img src="https://img.shields.io/badge/License-Open_Source-orange?style=flat&logo=opensource" alt="License">
  </a>
  <a href="https://aerlabs.tech/blogs.html">
    <img src="https://img.shields.io/badge/Blog-Technical_Deep_Dives-green?style=flat&logo=medium" alt="Blog">
  </a>
  <a href="https://forms.gle/q8LQ9dT8st4eFAD56">
    <img src="https://img.shields.io/badge/Hiring-We_Are_Hiring-important?style=flat" alt="Hiring">
  </a>
  <a href="mailto:daniel@aerlabs.tech">
    <img src="https://img.shields.io/badge/Contact-Email_Us-red?style=flat&logo=gmail" alt="Contact">
  </a>
</p>

---

## ‚ö° Latest News

-   **[2025/12]** üöÄ We released a **PyTorch native INT8 quantization API** for TorchAO, enabling INT8 inference with up to **4√ó memory reduction**. [Read the report](https://aerlabs.tech/research/int8tensor-torchao.html).
-   **[2025/12]** üåê We welcomed our **First Batch** of remote researchers working on open-source AI infrastructure.

---

## üìñ About
**AER Labs** is an open AI research lab focused on advancing AI systems across the full stack. Our vision is not just to optimize AI systems, but to remove the critical bottlenecks that prevent widespread adoption.

We work on:
-   **GPU Orchestration:** Efficient resource management for distributed GPU workloads.
-   **Inference Optimization:** KV cache optimization, quantization, and efficient attention mechanisms.
-   **Agentic AI:** Workflow orchestration and efficient serving for autonomous applications.

---

## üîë Key Features

AER Labs drives research in critical infrastructure areas:

-   **State-of-the-art Inference Optimization**
    -   High-throughput serving infrastructure.
    -   Custom CUDA/Triton kernels for quantization.
    -   Support for dynamic activation quantization (INT8√óINT8).

-   **Production-Grade Generative AI**
    -   **LLM Serving:** Optimized serving for large language models and multimodal systems.
    -   **Vertical AI:** Domain-specific solutions for quantitative finance and cybersecurity.

-   **Flexible Research Frameworks**
    -   **Deep Learning:** Novel architectures and training techniques.
    -   **Benchmarking:** Comprehensive comparison of serving frameworks (vLLM, SGLang, TGI).

---

## üõ† Getting Involved

We are actively recruiting for our next batch of researchers and developers.

-   **Apply Now:** [Join the First Batch](https://forms.gle/q8LQ9dT8st4eFAD56)
-   **Speaker Series:** Join sessions with experts from NVIDIA, AMD, and ByteDance. [View Events](https://aerlabs.tech/events.html)
-   **Read our Research:** Explore our technical deep dives. [Blog](https://aerlabs.tech/blogs.html)
---

## üìû Contact

For questions and collaborations, please reach out:

*   **General Inquiries:** [contact@aerlabs.tech](mailto:contact@aerlabs.tech)
